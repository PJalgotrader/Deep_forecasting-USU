{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4663e435",
   "metadata": {},
   "source": [
    "### Prof. Pedram Jahangiry\n",
    "\n",
    "![logo](https://upload.wikimedia.org/wikipedia/commons/4/44/Huntsman-Wordmark-with-USU-Blue.gif#center)\n",
    "\n",
    "## ðŸ”— Links\n",
    "\n",
    "[![linkedin](https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/pedram-jahangiry-cfa-5778015a)\n",
    "\n",
    "[![Youtube](https://img.shields.io/badge/youtube_channel-1DA1F2?style=for-the-badge&logo=youtube&logoColor=white&color=FF0000)](https://www.youtube.com/channel/UCNDElcuuyX-2pSatVBDpJJQ)\n",
    "\n",
    "[![Twitter URL](https://img.shields.io/twitter/url/https/twitter.com/PedramJahangiry.svg?style=social&label=Follow%20%40PedramJahangiry)](https://twitter.com/PedramJahangiry)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colab-gpu-guide",
   "metadata": {},
   "source": [
    "### VS Code + Colab GPU quickstart\n",
    "\n",
    "1. Install the official `Colab` extension (Google) from the VS Code Marketplace so you can open notebooks backed by Google Colab directly inside VS Code.\n",
    "2. Press `Ctrl+Shift+P` (`Cmd+Shift+P` on macOS), run **Colab: Sign in**, and authorize the Google account that owns your Drive/notebooks.\n",
    "3. In the Colab sidebar click **Connect** (or the server dropdown) and select the Colab backend you want VS Code to use; once connected the tab will show that the kernel runs on Colab.\n",
    "4. In that connection dialog choose the accelerator (**GPU** or **TPU**) before confirming so the remote runtime starts with the device you need.\n",
    "5. Now you can run the `!nvidia-smi` cell below to confirm that VS Code is executing on the Colab GPU machine.\n",
    "\n",
    "_Note: Free Colab GPU sessions can time out or disconnect after periods of inactivity, so keep work synced to Drive or Git as you go._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06eaf00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 14 17:41:58 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   77C    P0             30W /   70W |     838MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b34d6dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# check the version \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da67239f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9989345669746399}]\n"
     ]
    }
   ],
   "source": [
    "# import pipeline from transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "# create a text classification pipeline\n",
    "classifier = pipeline(\"text-classification\")\n",
    "# classify some text\n",
    "result = classifier(\"I love using transformers library!\")\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
